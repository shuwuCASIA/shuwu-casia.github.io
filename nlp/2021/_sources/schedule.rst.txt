
Schedule
========

**Note**: Future schedule is subject to minor change. Please refer to
Gradescope for HW due date.

Introduction
^^^^^^^^^^^^

-  Week 1 (Sep 8). **Overview**: NLP tasks and challenges, basic ML

   -  `notes <notes/overview.html>`__

Representation of text
^^^^^^^^^^^^^^^^^^^^^^

-  Week 2 (Sep 15). **Text classification**: bag-of-words, naive Bayes
   models, logistic regression

   -  `notes <notes/text_classification.html>`__

-  Week 3 (Sep 22). **Distributed representation**: vector space models,
   Brown clusters, neural word embeddings

   -  `notes <notes/distributed_representation.html>`__

Predicting sequences
^^^^^^^^^^^^^^^^^^^^

-  Week 4 (Sep 29). **Language models**: n-gram LM, neural LM,
   perplexity

   -  `notes <notes/language_models.html>`__

-  Week 5 (Oct 6). **Sequence labeling**: log-linear models, decoding,
   POS tagging

   -  `notes <notes/sequence_labeling.html>`__

-  Week 6 (Oct 13). **Hidden Markov models**: HMM, EM

   -  `J&M HMM <https://web.stanford.edu/~jurafsky/slp3/A.pdf>`__,
      `Collins EM <http://www.cs.columbia.edu/~mcollins/em.pdf>`__

-  Week 7 (Oct 20). Midterm.

Predicting trees
^^^^^^^^^^^^^^^^

-  Week 8 (Oct 27). **Context-free parsing**: PCFG, CYK, neural parser

   -  `Collins
      PCFG <http://www.cs.columbia.edu/~mcollins/courses/nlp2011/notes/pcfgs.pdf>`__,
      `Eisner
      Inside-Outside <http://www.cs.jhu.edu/~jason/465/readings/iobasics.pdf>`__

-  Week 9 (Nov 3). **Semantic parsing**: logical semantics, learning
   from logical forms / denotations

   -  E Ch12, `Liang
      16 <https://cs.stanford.edu/~pliang/papers/executable-cacm2016.pdf>`__

Deep learning for NLP
^^^^^^^^^^^^^^^^^^^^^

-  Week 10 (Nov 10). **Neural sequence modeling**: seq2seq, attention,
   copy mechanism, text generation

   -  D2L
      `9.7 <https://d2l.ai/chapter_recurrent-modern/seq2seq.html>`__,
      `9.8 <https://d2l.ai/chapter_recurrent-modern/beam-search.html>`__,
      `10 <https://d2l.ai/chapter_attention-mechanisms/index.html>`__

-  Week 11 (Nov 17). **Representation learning**: transformers,
   contextualized word embedding, pre-training and fine-tuning,
   autoencoders

   -  `Representation Learning: A Review and New
      Perspectives <https://arxiv.org/abs/1206.5538>`__

Beyond text
^^^^^^^^^^^

-  Week 12 (Nov 24). **Language grounding**: language+vision/robotics,
   pragmatics, RL agents

Conclusion
^^^^^^^^^^

-  Week 13 (Dec 1). **Summary and outlook**: summary of the course,
   fairness and ethics in NLP
-  Week 14 (Dec 8). **Project presentations**
